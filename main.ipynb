{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cffee03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-2.14.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp310-cp310-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/dberweger/Library/Python/3.10/lib/python/site-packages (from openai) (4.12.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/dberweger/Library/Python/3.10/lib/python/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.12.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/dberweger/Library/Python/3.10/lib/python/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/dberweger/Library/Python/3.10/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/dberweger/Library/Python/3.10/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /Users/dberweger/Library/Python/3.10/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/dberweger/Library/Python/3.10/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/dberweger/Library/Python/3.10/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached pydantic_core-2.41.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.3-cp310-cp310-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading openai-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.12.0-cp310-cp310-macosx_11_0_arm64.whl (319 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Using cached pydantic_core-2.41.5-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "Downloading numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.2-cp310-cp310-macosx_12_0_arm64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Using cached scipy-1.15.3-cp310-cp310-macosx_14_0_arm64.whl (22.4 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: typing-inspection, tqdm, threadpoolctl, sniffio, python-dotenv, pydantic-core, numpy, joblib, jiter, distro, annotated-types, scipy, pydantic, scikit-learn, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [openai]14/15\u001b[0m [openai]learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 distro-1.9.0 jiter-0.12.0 joblib-1.5.3 numpy-2.2.6 openai-2.14.0 pydantic-2.12.5 pydantic-core-2.41.5 python-dotenv-1.2.1 scikit-learn-1.7.2 scipy-1.15.3 sniffio-1.3.1 threadpoolctl-3.6.0 tqdm-4.67.1 typing-inspection-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai numpy scikit-learn python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb41d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427ffb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba2049b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<openai.OpenAI object at 0x115c69150>\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c008047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    \"\"\"\n",
    "    Turns text into a vector using OpenAI.\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d54a9245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector length: 1536\n",
      "First 5 dimensions: [0.009197094477713108, -0.03516796976327896, -0.025027744472026825, 0.039801329374313354, 0.001860940014012158]\n"
     ]
    }
   ],
   "source": [
    "word_vec = get_embedding(\"Apple\")\n",
    "\n",
    "print(f\"Vector length: {len(word_vec)}\") # Should be 1536 for this model\n",
    "print(f\"First 5 dimensions: {word_vec[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a79900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity (King vs Queen): 0.7240\n",
      "Similarity (King vs Apple): 0.3318\n"
     ]
    }
   ],
   "source": [
    "# Compare 3 words\n",
    "word_1 = get_embedding(\"King\")\n",
    "word_2 = get_embedding(\"Queen\")\n",
    "word_3 = get_embedding(\"Apple\")\n",
    "\n",
    "# Calculate similarity\n",
    "score_king_queen = cosine_similarity([word_1], [word_2])[0][0]\n",
    "score_king_apple = cosine_similarity([word_1], [word_3])[0][0]\n",
    "\n",
    "print(f\"Similarity (King vs Queen): {score_king_queen:.4f}\")\n",
    "print(f\"Similarity (King vs Apple): {score_king_apple:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "688bbde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: How do I write a function?\n",
      "Best Match Score: 0.4398\n",
      "Retrieved Context: Use 'def' to define a function in Python.\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"The golden retriever is a popular dog breed known for its gentle nature.\",\n",
    "    \"Python involves dynamic typing and garbage collection.\",\n",
    "    \"The weather in San Francisco is often foggy in the summer.\",\n",
    "    \"Use 'def' to define a function in Python.\"\n",
    "]\n",
    "\n",
    "# 1. Pre-calculate embeddings for our database\n",
    "doc_embeddings = [get_embedding(doc) for doc in documents]\n",
    "\n",
    "def retrieve_context(query, docs, doc_vecs):\n",
    "    \"\"\"\n",
    "    Finds the most relevant document for the query.\n",
    "    \"\"\"\n",
    "    # Embed the query\n",
    "    query_vec = get_embedding(query)\n",
    "    \n",
    "    # Calculate similarities\n",
    "    similarities = cosine_similarity([query_vec], doc_vecs)[0]\n",
    "    \n",
    "    # Find the index of the highest score\n",
    "    best_idx = np.argmax(similarities)\n",
    "    \n",
    "    return docs[best_idx], similarities[best_idx]\n",
    "\n",
    "# --- Test the Retrieval ---\n",
    "query = \"How do I write a function?\"\n",
    "context, score = retrieve_context(query, documents, doc_embeddings)\n",
    "\n",
    "print(f\"User Query: {query}\")\n",
    "print(f\"Best Match Score: {score:.4f}\")\n",
    "print(f\"Retrieved Context: {context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4384e6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Debug] Retrieved Info: Use 'def' to define a function in Python.\n",
      "\n",
      "--- Final Answer ---\n",
      "In Python, you use the keyword 'def' to define a function. Functions are blocks of code designed to perform a specific task. You can call a function whenever you need to execute that task. Functions can take inputs (called parameters) and can return outputs.\n"
     ]
    }
   ],
   "source": [
    "def ask_rag(query):\n",
    "    # Step 1: Retrieve relevant information (The \"R\")\n",
    "    best_context, score = retrieve_context(query, documents, doc_embeddings)\n",
    "    \n",
    "    print(f\"[Debug] Retrieved Info: {best_context}\")\n",
    "    \n",
    "    # Step 2: Generate Answer (The \"G\")\n",
    "    # We explicitly tell GPT to use the provided context.\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful assistant. Answer the user's question based ONLY on the context below.\n",
    "    \n",
    "    Context:\n",
    "    {best_context}\n",
    "    \n",
    "    Question: \n",
    "    {query}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", # or gpt-3.5-turbo\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# --- Run the Full RAG System ---\n",
    "answer = ask_rag(\"Tell me about coding functions\")\n",
    "print(\"\\n--- Final Answer ---\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
